{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas\n",
    "import cleaning_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing the data cleaning service. (just for the first usage time)\n",
    "If it is the first time that you want to run the data cleaning service on your system, you need to consider the following instructions:\n",
    "1. Make sure that you have installed\n",
    "    - Linux (Ubuntu/Debian recommended)\n",
    "    - Python 2.7\n",
    "    - Oracle Java 1.8\n",
    "    - Apache Ant 1.8.2+\n",
    "    - PostgreSQL 9.2+\n",
    "2. Call the following method to install data cleaing tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dBoost is installed.\n",
      "KATARA is installed.\n",
      "To configure NADEEF, please follow the following steps:\n",
      "1. Create a database entitled 'nadeef' in the postgres.\n",
      "2. Inter your postgres username: postgres\n",
      "3. Inter your postgres password: 1234\n",
      "NADEEF is installed.\n"
     ]
    }
   ],
   "source": [
    "cleaning_api.install_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entering path of input and output JSON files.\n",
    "For example,\n",
    "- As input: sources.json\n",
    "- As output: destination.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter path of input JSON file: sources.json\n",
      "Please enter path of output JSON file: destination.json\n"
     ]
    }
   ],
   "source": [
    "input_file_path = raw_input(\"Please enter path of input JSON file: \")\n",
    "output_file_path = raw_input(\"Please enter path of output JSON file: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the input and output JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dictionary = json.load(open(input_file_path, \"r\"))\n",
    "input_folder = input_dictionary[\"CSV\"][\"dir\"]\n",
    "if input_dictionary[\"CSV\"][\"table\"]:\n",
    "    input_tables = input_dictionary[\"CSV\"][\"table\"].split(\";\")\n",
    "else:\n",
    "    input_tables = os.listdir(input_folder)\n",
    "output_dictionary = json.load(open(output_file_path, \"r\"))\n",
    "output_folder = output_dictionary[\"CSV\"][\"dir\"]\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating over the input dataset tables and running data cleaning tools.\n",
    "Available data cleaning tools are:\n",
    "- **dboost**\n",
    "    - Recommended parameters for dboost are:\n",
    "        - [\"gaussian\", \"2\"]\n",
    "        - [\"histogram\", \"0.8\", \"0.2\"]\n",
    "        - [\"mixture\", \"2\", \"0.01\"]\n",
    "        - [\"partitionedhistogram\", \"10\", \"0.8\", \"0.1\"]    \n",
    "- **nadeef**\n",
    "    - Proper parameter for nadeef is list of existing functional dependencies in the dataset. For example,\n",
    "    \n",
    "    [[\"A\", \"B\"], [\"X, Y\", \"Z\"]]\n",
    "    \n",
    "    means that the functional dependencies A -> B and X, Y -> Z exist among the attributes A, B, X, Y, and Z in the dataset.\n",
    "- **openrefine**\n",
    "    - Proper parameter for the openrefine is list of existing patterns for different attributes of the dataset. For example,\n",
    "    \n",
    "    [[\"A\", \"`^[\\d]{3}$`\"], [\"B\", \"`^[A-Za-z]+$`\"]]\n",
    "    \n",
    "    means that the attribute A must have only 3-digit values and the attribute B must have only alphabetical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset's atributes are:\n",
      "[u'title', u'url', u'model', u'mileage', u'price', u'contact_number', u'vtype', u'brand_name']\n",
      "Please enter the name of data cleaning tool: nadeef\n",
      "Please enter the proper parameter list: [[\"title\", \"brand_name\"]]\n",
      "The results have been written into the outputs/sample.csv\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for table in input_tables:\n",
    "    dataset_path = os.path.join(input_folder, table)\n",
    "    table_data = cleaning_api.read_csv_dataset(dataset_path)\n",
    "    print \"The dataset's atributes are:\"\n",
    "    print table_data[0]\n",
    "    # df = pandas.DataFrame(data=table_data[1:], columns=table_data[0])\n",
    "    # print df.head()[[\"price\", \"^[\\d]+$\"], [\"brand_name\", \"^[\\w]+$\"]]\n",
    "    tool_name = raw_input(\"Please enter the name of data cleaning tool: \")\n",
    "    exec(\"tool_parameters = \" + raw_input(\"Please enter the proper parameter list: \"))\n",
    "    run_input = {\n",
    "        \"dataset\": {\n",
    "            \"type\": \"csv\",\n",
    "            \"param\": [dataset_path]\n",
    "        },\n",
    "        \"tool\": {\n",
    "            \"name\": tool_name,\n",
    "            \"param\": tool_parameters\n",
    "            }\n",
    "    }\n",
    "    results_list = cleaning_api.run_data_cleaning_job(run_input)\n",
    "    result_path = os.path.join(output_folder, table)\n",
    "    cleaning_api.write_csv_dataset(result_path, [[\"row\", \"column\", \"value\"]] + results_list)\n",
    "    print \"The results have been written into the {}\\n--------------------------------------\".format(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
